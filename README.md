<p align="center">
  <img src="assets/logo.png" alt="Siraj Logo" width="150"/>
</p>

<h1 align="center">Siraj â€“ Your Arabic AI Learning Companion</h1>

---

## ðŸš€ About Siraj

**Siraj** is an Arabic AI-powered educational assistant designed to answer user queries in natural Arabic, leveraging speech and visual input. The app helps users practice language, ask questions, and engage in spoken conversations powered by Large Language Models (LLMs), with support for audio responses, lip-sync, and emotion-aware 3D avatar feedback.

The app was conceptualized and prototyped during the **QCRI Intern Hackathon** in **July 2025** by a team of interns at **Qatar Computing Research Institute (QCRI), HBKU**, as part of a research initiative to make Arabic LLMs more accessible and educationally impactful.

Siraj is built with modularity in mind â€” from backend APIs integrating Gemini and emotion detection, to a 3D web frontend with avatar animation and voice synthesis.

---

## ðŸ’¡ Key Features

- ðŸ”Š **Voice-based interaction** in Arabic with transcription and text-to-speech
- ðŸ§  **LLM integration** using Google's Gemini API for Arabic Q&A and chat
- ðŸŽ­ **Emotion detection** to personalize avatar reactions
- ðŸ‘„ **Lip-sync** with audio using Rhubarb Lip Sync
- ðŸ§â€â™‚ï¸ **3D Avatar** rendered with Three.js and iframe in Flutter Web
- ðŸ“· **Visual QA (planned)** â€“ ask questions about images (e.g., "What is in this photo?")
- ðŸ“š Designed to support **Arabic education and accessibility use cases**

---

## ðŸ§‘â€ðŸ’» Tech Stack

| Layer           | Technologies Used |
|----------------|-------------------|
| **Frontend**   | Flutter Web, iframe + HtmlElementView (for 3D avatar) |
| **Avatar UI**  | Three.js, WebGL, GLB model, Rhubarb lip sync JSON |
| **Backend**    | Node.js, Express, Python (emotion detection), gTTS |
| **APIs Used**  | Google Generative AI (Gemini), Fanar Arabic ASR API |
| **TTS**        | gTTS (Google Text-to-Speech) |
| **Lip-Sync**   | Rhubarb Lip Sync |
| **Emotion Detection** | Python (facial emotion classifier) |

---

## ðŸ›  Project Structure

siraj/
â”œâ”€â”€ assets/
â”‚ â””â”€â”€ logo.png
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.js (Node/Express server)
â”‚ â”œâ”€â”€ emotion_detector.py
â”‚ â””â”€â”€ routes/chat.js
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ lib/
â”‚ â”‚ â””â”€â”€ views/ask_siraj_view.dart
â”‚ â””â”€â”€ web/
â”‚ â””â”€â”€ avatar.html (3D avatar scene)
â”œâ”€â”€ models/
â”‚ â””â”€â”€ modelguy.glb
â””â”€â”€ README.md


---

## ðŸ§ª Development History

- ðŸ’¡ **July 2025**: Idea formed and prototype developed during **QCRI Intern Hackathon**
- ðŸ¤ Built by a team of QCRI interns during the summer internship program
- ðŸ“ˆ Focused on **Arabic education**, **spoken QA**, and **emotion-aware avatar interaction**

---

## ðŸ—‚ Related Work

Even though the formal internship was not continued, contributions to **data annotation tasks** for QCRI projects are **ongoing**, including:

- **Spoken QA Dataset Collection**: Recording various Arabic question types (MCQ, open-ended, true/false) to train speech-based LLMs.
- **Image QA Auditing**: Verifying model-generated answers, rationales, and image relevance under expert supervision.

---

## ðŸ¤ Acknowledgements

- **Qatar Computing Research Institute (QCRI)** for mentorship and infrastructure.
- **Fanar Arabic API** for speech transcription.
- All fellow QCRI interns who contributed to brainstorming, testing, and building the early prototype of Siraj.

---

## ðŸ“¸ Screenshots

> Add screenshots or GIFs here to demonstrate the app in action.

---

## ðŸ“œ License

MIT License â€“ see [`LICENSE`](LICENSE) file for details.

---

